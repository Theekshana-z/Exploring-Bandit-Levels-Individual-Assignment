#  Exploring Bandit Levels — Individual Assignment

**Course:** SNP Module (2nd Year, 1st Semester – Individual Labsheet Project)

---

##  Project Overview

This project explores the concept of **Bandit problems**, a foundational topic in reinforcement learning and decision theory. By implementing and analyzing multi-armed bandit algorithms, the assignment aims to compare how different strategies perform in terms of exploration vs. exploitation.

---


##  Key Topics & Features

- Overview of Bandit problem setup and the explore-exploit dilemma.
- - Performance metrics and graphical comparisons to show algorithm efficiency.
- Insights, findings, and lessons learned from implementing and comparing strategies.
- Description of algorithms such as ε-greedy, UCB (Upper Confidence Bound), and Thompson Sampling.

---

##  How to Explore the Project

1. **Clone** the repository:
   ```bash
   git clone https://github.com/Theekshana-z/Exploring-Bandit-Levels-Individual-Assignment.git
